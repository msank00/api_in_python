{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stub methods for ML pipeline stages\n",
    "Feel free to change/adapt/implement/delete as needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    load_data loads data from source\n",
    "\n",
    "    @type file_path: string\n",
    "    @param file_path: file path to the data source, e.g. a csv file\n",
    "    \n",
    "    @rtype: pandas.DataFrame\n",
    "    @return: Returns a (pandas) dataframe\n",
    "    \"\"\"\n",
    "    print(\"Start load_data\")\n",
    "    # Your code goes here\n",
    "    df_raw = None\n",
    "    print(\"End load_data\")\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    clean_data cleans/pre-processes data \n",
    "\n",
    "    @type df: pandas.DataFrame\n",
    "    @param df: dataframe of raw data\n",
    "    \n",
    "    @rtype: pandas.DataFrame\n",
    "    @return: the cleaned data\n",
    "    \"\"\"\n",
    "    print(\"Start clean_data\")\n",
    "    # Your code goes here\n",
    "    df_clean = None\n",
    "    print(\"End clean_data\")\n",
    "    return df_clean    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(df1, df2):\n",
    "    \"\"\"\n",
    "    clean_data cleans/pre-processes data \n",
    "\n",
    "    @type df1: pandas.DataFrame\n",
    "    @param df1: dataframe #1 with cleaned data\n",
    "\n",
    "    @type df2: pandas.DataFrame\n",
    "    @param df2: dataframe #2 with cleaned data\n",
    "\n",
    "    @rtype: pandas.DataFrame\n",
    "    @return: the joined data\n",
    "    \"\"\"\n",
    "    print(\"Start join_data\")\n",
    "    # Your code goes here\n",
    "    df_joined = None\n",
    "    print(\"End join_data\")\n",
    "    return df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    \"\"\"\n",
    "    clean_data clean/pre-processes data \n",
    "\n",
    "    @type df: pandas.DataFrame\n",
    "    @param df: dataframe with data to filter\n",
    "\n",
    "    @rtype: pandas.DataFrame\n",
    "    @return: the joined data\n",
    "    \"\"\"\n",
    "    print(\"Start filter_data\")\n",
    "    # Your code goes here\n",
    "    df_filtered = None\n",
    "    print(\"End filter_data\")\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(df):\n",
    "    \"\"\"\n",
    "    explore_data explore your data in whatever way you wish! \n",
    "\n",
    "    @type df: pandas.DataFrame\n",
    "    @param df: dataframe of data\n",
    "    \"\"\"\n",
    "    print(\"Start explore_data\")\n",
    "    # Your code goes here. Can well happen that there are no return values in this function.\n",
    "    print(\"End explore_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    engineer_features use this function to engineer your features \n",
    "\n",
    "    @type df: pandas.DataFrame\n",
    "    @param df: dataframe ready for feature engineering\n",
    "\n",
    "    @rtype: pandas.DataFrame\n",
    "    @return: dataframe with new features\n",
    "    \"\"\"\n",
    "    print(\"Start engineer_features\")\n",
    "    # Your code goes here\n",
    "    df_engineered = None\n",
    "    print(\"End engineer_features\")\n",
    "    return df_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test_data(df):\n",
    "    \"\"\"\n",
    "    split_train_and_test_data use this function to split the input dataframe into two dataframes containing train and test data\n",
    "\n",
    "    @type df: pandas.DataFrame\n",
    "    @param df: dataframe ready to be split into train and test data\n",
    "\n",
    "    @rtype: (pandas.DataFrame, pandas.DataFrame)\n",
    "    @return: a tuple (df_train, df_test) containing training data in the first position, and test data in the second position\n",
    "    \"\"\"\n",
    "    print(\"Start split_train_and_test_data\")\n",
    "    # Your code goes here\n",
    "    df_train = None\n",
    "    df_test = None\n",
    "    print(\"End split_train_and_test_data\")\n",
    "    return (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    \"\"\"\n",
    "    train_model use this function to actually train the model\n",
    "\n",
    "    @type df: pandas.DataFrame\n",
    "    @param df: dataframe containing training data\n",
    "\n",
    "    @rtype: <to be determined, potentially scikit-learn model>\n",
    "    @return: the trained model\n",
    "    \"\"\"\n",
    "    print(\"Start train_model\")\n",
    "    # Your code goes here\n",
    "    model = None\n",
    "    print(\"End train_model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, df):\n",
    "    \"\"\"\n",
    "    test_model use this function to apply the model on the out-of-sample test data\n",
    "\n",
    "    @type model: pandas.DataFrame\n",
    "    @param model: dataframe containing out-of-sample test data\n",
    "\n",
    "    @type df: pandas.DataFrame\n",
    "    @param df: dataframe containing out-of-sample test data\n",
    "    \n",
    "    @rtype: <to be determined, potentially simply nothing>\n",
    "    @return: probably simply nothing\n",
    "    \"\"\"\n",
    "    print(\"Start validate_model\")\n",
    "    # Your code goes here\n",
    "    print(\"End validate_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, target_file_path):\n",
    "    \"\"\"\n",
    "    save_model use this function to save the model to the target destination file path\n",
    "\n",
    "    @type model: <to be determined, potentially scikit-learn model>\n",
    "    @param df: dataframe containing training data\n",
    "    \n",
    "    @type target_file_path: string\n",
    "    @param target_file_path: the target file path where to save the serialized model to\n",
    "    \n",
    "    @rtype: <to be determined, potentially simply nothing>\n",
    "    @return: maybe a file pointer, or simply nothing\n",
    "    \"\"\"\n",
    "    print(\"Start save_model\")\n",
    "    # Your code goes here\n",
    "    print(\"End save_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML pipeline code\n",
    "After having implemented code stubs for each of above ML pipeline stages, you can run your code below in the natural order of the ML pipeline. This could also be done within a single _main()_ method. Feel free to add outputs and graphics after each stage as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start load_data\n",
      "End load_data\n"
     ]
    }
   ],
   "source": [
    "data_file_path = \"data/foo.csv\"\n",
    "df_raw = load_data(data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start clean_data\n",
      "End clean_data\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = clean_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cleaned_2 = ...\n",
    "#df_joined = join_data(df_cleaned, df_cleaned2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start filter_data\n",
      "End filter_data\n"
     ]
    }
   ],
   "source": [
    "df_filtered = filter_data(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start explore_data\n",
      "End explore_data\n"
     ]
    }
   ],
   "source": [
    "explore_data(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start engineer_features\n",
      "End engineer_features\n"
     ]
    }
   ],
   "source": [
    "df_engineered = engineer_features(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start split_train_and_test_data\n",
      "End split_train_and_test_data\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = split_train_and_test_data(df_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train_model\n",
      "End train_model\n"
     ]
    }
   ],
   "source": [
    "model = train_model(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validate_model\n",
      "End validate_model\n"
     ]
    }
   ],
   "source": [
    "validate_model(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start save_model\n",
      "End save_model\n"
     ]
    }
   ],
   "source": [
    "target_file_path = \"\"\n",
    "save_model(model, target_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
